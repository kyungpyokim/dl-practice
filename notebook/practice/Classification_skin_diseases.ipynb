{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcb7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import datasets\n",
    "\n",
    "data_dir = '../../dataset/skin_diseases/train'\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    list(range(len(full_dataset))),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=full_dataset.targets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec25b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "train_dataset = Subset(full_dataset, train_idx)\n",
    "test_dataset = Subset(full_dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe05081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee20aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(f'image : {image}, label : {label}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22e98a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def imshow(image, title):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406])\n",
    "    std = torch.tensor([0.229, 0.224, 0.225])\n",
    "    image = image.permute(1, 2, 0)\n",
    "    image = image * std + mean  # 역정규화\n",
    "    # [0.485, 0.456, 0.406]\n",
    "    # [0.229, 0.224, 0.225]\n",
    "    plt.title(title)\n",
    "    plt.imshow(image)  # permute 차원 순서 변경\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606fc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchvision\n",
    "\n",
    "# data_iter = iter(train_loader)\n",
    "# images, labels = next(data_iter)\n",
    "\n",
    "# out_images = torchvision.utils.make_grid(images)\n",
    "\n",
    "# imshow(out_images, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d415edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torchvision import models\n",
    "\n",
    "from lib.model import create_model\n",
    "\n",
    "weights = models.ResNet34_Weights.DEFAULT\n",
    "rnet34_model = create_model(models.resnet34(weights=weights), name='ResNet34')\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "print(f'평균(Mean): {preprocess.mean}')\n",
    "print(f'표준편차(Std): {preprocess.std}')\n",
    "print(f'권장 이미지 크기: {preprocess.resize_size}')\n",
    "\n",
    "print(rnet34_model)\n",
    "# for name, module in rnet34_model.named_parameters():\n",
    "#     print(name, module.requires_grad)\n",
    "\n",
    "for params in rnet34_model.parameters():\n",
    "    params.requires_grad = False  # 가중치를 고정 frozen\n",
    "\n",
    "rnet34_model.fc = nn.Linear(512, 5)  # 마지막 나올 fc만 수정 # 모델의 분류기만 바꿈\n",
    "rnet34_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586de7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import create_loader, set_transform\n",
    "from lib.train import eval_model, train_model\n",
    "from lib.transform import create_transform\n",
    "\n",
    "train_transform, test_transform = create_transform(\n",
    "    (256, 256), preprocess.mean, preprocess.std\n",
    ")\n",
    "\n",
    "train_dataset_final, test_dataset_final = set_transform(\n",
    "    (train_dataset, test_dataset), (train_transform, test_transform)\n",
    ")\n",
    "\n",
    "train_loader, test_loader = create_loader(train_dataset_final, test_dataset_final)\n",
    "\n",
    "rnet34_model.train()\n",
    "train_model(rnet34_model, train_loader, lr=1e-4, epochs=30)\n",
    "eval_model(rnet34_model, test_loader, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "weights = models.ConvNeXt_Base_Weights.DEFAULT\n",
    "conv_model = models.convnext_base(weights=weights)\n",
    "conv_model.arc_name = 'convnext'\n",
    "\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "print(f'평균(Mean): {preprocess.mean}')\n",
    "print(f'표준편차(Std): {preprocess.std}')\n",
    "print(f'권장 이미지 크기: {preprocess.resize_size}')\n",
    "\n",
    "print(conv_model)\n",
    "\n",
    "for name, module in conv_model.named_parameters():\n",
    "    print(name, module.requires_grad)\n",
    "\n",
    "for params in conv_model.parameters():\n",
    "    params.requires_grad = False  # 가중치를 고정 frozen\n",
    "\n",
    "conv_model.classifier[2] = nn.Linear(1024, 5)\n",
    "\n",
    "print(conv_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf010305",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import create_loader, set_transform\n",
    "from lib.train import eval_model, train_model\n",
    "from lib.transform import create_transform\n",
    "\n",
    "train_loader, test_loader = create_loader(train_dataset, test_dataset, 32)\n",
    "\n",
    "train_transform, test_transform = create_transform(\n",
    "    (232, 232), preprocess.mean, preprocess.std\n",
    ")\n",
    "\n",
    "set_transform((train_dataset, test_dataset), (train_transform, test_transform))\n",
    "\n",
    "train_model(conv_model, train_loader, 10)\n",
    "eval_model(conv_model, test_loader, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e747ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "weights = models.EfficientNet_V2_S_Weights.DEFAULT\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "eff_net_model = models.efficientnet_v2_s(weights=weights)\n",
    "eff_net_model.arc_name = 'eff_net'\n",
    "\n",
    "print(f'평균(Mean): {preprocess.mean}')\n",
    "print(f'표준편차(Std): {preprocess.std}')\n",
    "print(f'권장 이미지 크기: {preprocess.resize_size}')\n",
    "\n",
    "eff_net_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616a6478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "for params in eff_net_model.parameters():\n",
    "    params.requires_grad = False  # 가중치를 고정 frozen\n",
    "\n",
    "\n",
    "eff_net_model.classifier[1] = nn.Linear(1280, 5)\n",
    "\n",
    "print(eff_net_model.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.dataset import create_loader, set_transform\n",
    "from lib.train import eval_model, train_model\n",
    "from lib.transform import create_transform\n",
    "\n",
    "train_loader, test_loader = create_loader(train_dataset, test_dataset, 32)\n",
    "\n",
    "train_transform, test_transform = create_transform(\n",
    "    (384, 384), preprocess.mean, preprocess.std\n",
    ")\n",
    "\n",
    "set_transform((train_dataset, test_dataset), (train_transform, test_transform))\n",
    "\n",
    "train_model(eff_net_model, train_loader)\n",
    "eval_model(eff_net_model, test_loader, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from lib.path import model_file_path\n",
    "\n",
    "\n",
    "def save_checkpoint(ep, model, optim, loss):\n",
    "    torch.save(\n",
    "        {\n",
    "            'epoch': ep,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'loss': loss,\n",
    "        },\n",
    "        model_file_path(f'{model.arc_name}_checkpoint.pth'),\n",
    "    )\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optim, device):\n",
    "    path = model_file_path('checkpoint.pth')\n",
    "\n",
    "    # 1. 파일 존재 여부 먼저 확인 (경로 오류 방지)\n",
    "    if not os.path.exists(path):\n",
    "        return 0\n",
    "    try:\n",
    "        # 2. weights_only=True로 로드 속도 및 안정성 향상 (PyTorch 최신버전 권장)\n",
    "        checkpoint = torch.load(path, map_location=device)\n",
    "        if checkpoint:\n",
    "            # 3. 모델 가중치 로드\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "            # 4. 옵티마이저 로드 (이 과정에서 메모리 점유가 늘어남)\n",
    "            if 'optimizer_state_dict' in checkpoint:\n",
    "                optim.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "            # 5. 메모리 정리 (중요!)\n",
    "            del checkpoint\n",
    "            torch.cuda.empty_cache()  # GPU 사용 시\n",
    "\n",
    "            return checkpoint.get('epoch', 0)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(f'체크포인트 로드 중 오류 발생: {e}')\n",
    "        # 여기서 커널이 죽는다면 대부분 메모리 부족입니다.\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0671510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import tqdm\n",
    "from torch import optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from lib.path import output_path\n",
    "\n",
    "log_dir = output_path() / 'tensorboard' / datetime.now().strftime('%Y%m%d')\n",
    "print(log_dir)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "optimizer = optim.Adam(eff_net_model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "epochs = 20\n",
    "eff_net_model = eff_net_model.to(device)\n",
    "\n",
    "start_ep = load_checkpoint(eff_net_model, optim, device)\n",
    "start_ep = start_ep > 0 if start_ep else -1\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ep in range(start_ep + 1, epochs):\n",
    "    train_tqdm = tqdm.tqdm(train_loader)\n",
    "    for image, labels in train_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        preds = eff_net_model(image.to(device))\n",
    "        loss = criterion(preds, labels.to(device))\n",
    "        writer.add_scalar('Loss/train', loss, count)\n",
    "        count += 1\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_tqdm.set_description(f'epoch : {ep} loss : {loss.item():.2f}')\n",
    "\n",
    "    save_checkpoint(ep, eff_net_model, optimizer, loss)\n",
    "\n",
    "print('Complted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4257012",
   "metadata": {},
   "outputs": [],
   "source": [
    "eff_net_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    corrects = 0\n",
    "\n",
    "    for image, labels in test_loader:\n",
    "        preds = eff_net_model(image.to(device))\n",
    "        pred = torch.max(preds, 1)[1]\n",
    "\n",
    "        corrects += torch.sum(pred == labels.to(device).data)\n",
    "\n",
    "        image_grid = torchvision.utils.make_grid(image)\n",
    "        print(labels)\n",
    "        imshow(image_grid.cpu(), title=pred)\n",
    "\n",
    "    print(corrects, len(test_dataset))\n",
    "    acc = corrects / len(test_dataset)\n",
    "    print(f'정확도 : {acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_practice (3.11.14)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
